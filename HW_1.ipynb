{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e83ad87-8665-4c08-98f6-d16187ba00a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a20fb97-5bba-41a8-a375-32b4e83b0c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e912d62e-538b-4067-9558-71dc50d8e0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "994e4585-21de-4e16-91e3-12fffdbccdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2a401df-b975-47f9-868b-5eec8687e3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0829f46-abd8-4586-9cde-68c6d0a559ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/arinkazam/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/arinkazam/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm import tqdm\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3933faa-00c4-4adc-a830-f8054b75aa9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fake_useragent import UserAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c1c8ea0-700e-4969-988c-08f3506988ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd282b0f-13ac-402c-9da8-9fc93075ccc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymorphy2 import MorphAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84a5e8f9-b651-4fc3-914b-b5f381adddf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50d6221b-75d5-4fab-b2e5-70264ec2b35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# имитируем пользователя и скачиваем основную страницу со списками отелей с сайта 101hotels.com\n",
    "ua = UserAgent()\n",
    "headers = {'User-Agent': ua.random}\n",
    "session = requests.session()\n",
    "response = session.get('https://m.101hotels.com/main/cities/moskva/inexpensive', headers=headers)\n",
    "page = response.text\n",
    "soup = BeautifulSoup(page, 'html.parser')\n",
    "looking_for_reviews = soup.find_all('div', {'class': 'hotel__title pr-5'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3a16d92-7efd-4dd1-94b1-40c9bfe78394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# скачиваем отзывы, размеченные как позитивные, они выведены на страницах отелей в разделе \"что гостям понравилось\"\n",
    "reviews_positive = []\n",
    "for item in looking_for_reviews:\n",
    "    link = item.find('a').attrs['href']\n",
    "    full_link = 'https://m.101hotels.com' + link\n",
    "    fragm = session.get(full_link, headers=headers).text\n",
    "    soup_fragm = BeautifulSoup(fragm, 'html.parser')\n",
    "    reviews_fragm = soup_fragm.find_all('div', {'class': 'hotel-top-reviews__text'})\n",
    "    for elem in reviews_fragm:\n",
    "        review = elem.find('div', {'class': 'response__text-full'}).text\n",
    "        reviews_positive.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c42a1ff4-3842-499c-88d1-0da5a30c7fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# скачиваем негативные отзывы, их можно найти в разделе всех отзывов под меткой \"response__text response__text_dislike\"\n",
    "reviews_negative = []\n",
    "for item in looking_for_reviews:\n",
    "    link = item.find('a').attrs['href']\n",
    "    full_link = 'https://m.101hotels.com' + link\n",
    "    fragm = session.get(full_link, headers=headers).text\n",
    "    soup_fragm = BeautifulSoup(fragm, 'html.parser')\n",
    "    reviews_link = 'https://m.101hotels.com' + soup_fragm.find('div', {'class': 'hotel-rating-item__text'}).find('a').attrs['href']\n",
    "    reviews_page = session.get(reviews_link, headers=headers).text\n",
    "    reviews_content = BeautifulSoup(reviews_page, 'html.parser')\n",
    "    negative_options = reviews_content.select_one('div', {'class': 'response__content'}).find_all('div', {'class': 'response__text response__text_dislike'})\n",
    "    for i in negative_options:\n",
    "        reviews_negative.append(i.text)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dacf0a1d-5f5a-4506-bcc2-882df845b343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем баланс классов\n",
    "if len(reviews_negative) > len(reviews_positive):\n",
    "    reviews_negative = reviews_negative[:len(reviews_positive)]\n",
    "else:\n",
    "    reviews_positive = reviews_positive[:len(reviews_negative)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1dde07bb-3fb7-4507-9443-a2003eeb3581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем датасет с отзывами\n",
    "data = {}\n",
    "data['text'] = []\n",
    "data['target'] = []\n",
    "for post in reviews_positive:\n",
    "    data['text'].append(post)\n",
    "    data['target'].append(1)\n",
    "for post_neg in reviews_negative:\n",
    "    data['text'].append(post_neg)\n",
    "    data['target'].append(0)\n",
    "df = pd.DataFrame(data)\n",
    "df = shuffle(df)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "734f0aef-a221-4696-9309-9a24dd5d0fb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Мягкий очень матрас, на любителя, нет ведра и ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>От метро близко, но будьте готовы идти по темн...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Очень уставшие номера морально и физически, но...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Чисто,аккуратно,в номера есть все необходимое,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Красивое здание, красивые стены и двери, пол к...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>Уже не первый раз останавливаюсь в этой гостин...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>Хотелось бы, чтоб отели уходили от ковровых на...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>Понравился вежливый персонал, внутренний социу...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>Отличное расположение-близость метро и большог...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>Мы из бывшего СССР! Поэтому обстановка порадов...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>248 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  target\n",
       "0    Мягкий очень матрас, на любителя, нет ведра и ...       0\n",
       "1    От метро близко, но будьте готовы идти по темн...       0\n",
       "2    Очень уставшие номера морально и физически, но...       1\n",
       "3    Чисто,аккуратно,в номера есть все необходимое,...       1\n",
       "4    Красивое здание, красивые стены и двери, пол к...       1\n",
       "..                                                 ...     ...\n",
       "243  Уже не первый раз останавливаюсь в этой гостин...       1\n",
       "244  Хотелось бы, чтоб отели уходили от ковровых на...       0\n",
       "245  Понравился вежливый персонал, внутренний социу...       1\n",
       "246  Отличное расположение-близость метро и большог...       1\n",
       "247  Мы из бывшего СССР! Поэтому обстановка порадов...       1\n",
       "\n",
       "[248 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# выводим пример того, как выглядит датасет\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "654735e8-dbbf-419b-a3c1-dc4648dc1740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# сохраняем датасет в файл на будущее\n",
    "df.to_csv('pos_neg_posts_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98562175-66a7-4eec-b8c9-1ae3e7f10cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = MorphAnalyzer()\n",
    "stop_w = set(stopwords.words('russian'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b162e3d-0859-4ac0-ac5c-292e034caf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем функцию для препроцессинга отзывов\n",
    "def preprocessing(arr):\n",
    "    corpus=[]\n",
    "    for text in tqdm(arr):\n",
    "        text = text.replace('\\r\\n', ' ')\n",
    "        words=[word.lower() for word in word_tokenize(text) if ((word.isalpha() == 1) & (word not in stop_w))]\n",
    "        lemmatized_output = ' '.join([morph.parse(w)[0].normal_form for w in words])\n",
    "        corpus.append(lemmatized_output)\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e8d2ddf6-e6fc-4d96-bf9b-12a7f8618328",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 248/248 [00:02<00:00, 109.15it/s]\n"
     ]
    }
   ],
   "source": [
    "# применяем функцию к датасету, разбиваем датасет на признаки и целевую переменную\n",
    "df['text'] = preprocessing(df['text'])\n",
    "df_x = df['text']\n",
    "df_y = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f5ea92d-f768-400a-b338-fad0410d95c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# разбиваем датасет на тренировочную и тестовую выборку\n",
    "np.random.seed(11)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_x, df_y, test_size=0.3, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f056c328-5dd2-44c2-8b22-78d8a73b1b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# делаем список только позитивных и только негативных отзывов из датафрейма, смотрим пересечение, смотрим частотность\n",
    "reviews_positive_train = list(X_train[y_train == 1])\n",
    "reviews_negative_train = list(X_train[y_train == 0])\n",
    "\n",
    "positive_words = (' '.join(reviews_positive_train)).split()\n",
    "dict_positive_apppear = Counter(positive_words)\n",
    "negative_words = (' '.join(reviews_negative_train)).split()\n",
    "dict_negative_apppear = Counter(negative_words)\n",
    "\n",
    "set_positive_words = set(positive_words)\n",
    "set_negative_words = set(negative_words)\n",
    "in_both_types = set_positive_words & set_negative_words\n",
    "\n",
    "list_positive_words = list(set_positive_words)\n",
    "list_negative_words = list(set_negative_words)\n",
    "list_in_both_types = list(in_both_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "649ab829-7e54-475c-94cf-735434d90f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# убираем пересечение слов негативных и позитивных отзывов из обоих списков\n",
    "i = 0\n",
    "j = 0\n",
    "while i < len(list_positive_words):\n",
    "    if list_positive_words[i] in list_in_both_types:\n",
    "        list_positive_words.pop(i)\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "while j < len(list_negative_words):\n",
    "    if list_negative_words[j] in list_in_both_types:\n",
    "        list_negative_words.pop(j)\n",
    "    else:\n",
    "        j += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "548ec70b-fbae-4e82-9d5e-f7ef7eff70f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# пробуем учесть частотности слов и их длину (так могут исключиться вещи, которые не вошли в стоп-слова, но могут ими считаться)\n",
    "t = 0\n",
    "k = 0\n",
    "while t < len(list_positive_words):\n",
    "    if dict_positive_apppear[list_positive_words[t]] < 3 or len(list_positive_words[t]) < 3:\n",
    "        list_positive_words.pop(t)\n",
    "    else:\n",
    "        t += 1\n",
    "\n",
    "while k < len(list_negative_words):\n",
    "    if dict_negative_apppear[list_negative_words[k]] < 3 or len(list_negative_words[k]) < 3:\n",
    "        list_negative_words.pop(k)\n",
    "    else:\n",
    "        k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e640b1b2-258b-4108-92c4-c70707d24188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем итоговые множества позитивных и негативных слов из отзывов\n",
    "only_positive = set(list_positive_words)\n",
    "only_negative = set(list_negative_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d1c3c3f7-5903-477b-8492-653e9d91ec29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем функцию классификации отзывов по имеющимся множествам позитивных и негативных слов из отзывов \n",
    "def predict_tone(arr, pos_l, neg_l):\n",
    "    ans = []\n",
    "    for text in arr:\n",
    "        content = set(text.split())\n",
    "        # считаем, каких вхождений больше, выводим превалирующее\n",
    "        if len(content & pos_l) > len(content & neg_l):\n",
    "            ans.append(1)\n",
    "        else:\n",
    "            ans.append(0)\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9e94017e-51be-4e6c-9377-984b1be698a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем функцию для подсчета accuracy\n",
    "def accuracy_score(prediction, y):\n",
    "    return (len(prediction) - np.sum(np.absolute(np.array(prediction) - np.array(y)))) / len(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e39f80d4-4b6d-4800-836c-48d606e416d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# делаем предсказание на тренировочной и тестовых выборках\n",
    "predicted_train = predict_tone(X_train, only_positive, only_negative)\n",
    "predicted_test = predict_tone(X_test, only_positive, only_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c78b30c6-5649-46e6-aac5-95532d20c820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train = 0.9826589595375722\n",
      "test = 0.8266666666666667\n"
     ]
    }
   ],
   "source": [
    "# выводим accuracy для тренировочной и тестовой выборок\n",
    "print(f\"train = {accuracy_score(predicted_train, y_train)}\")\n",
    "print(f\"test = {accuracy_score(predicted_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36097a5d-e492-4883-86aa-4a7dd933f266",
   "metadata": {},
   "source": [
    "#### Как улучшить алгоритм:\n",
    "\n",
    "1. попробуем использовать биграммы вместо одиночных слов\n",
    "   \n",
    "2. векторизация текста и подсчет евклидовой метрики между векторами тренировочной и тестовой выборок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "55fd0c30-4624-4246-a905-82e6b7b1bf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# реализация первого способа, функция для поиска биграмм позитивных и негативных отзывов\n",
    "def bigrams_search(arr):\n",
    "    bigrams = []\n",
    "    for text in tqdm(arr):\n",
    "        text_new = re.findall(r'[^\\s]+[\\s][^\\s]+', text)        \n",
    "        for bigram in text_new:\n",
    "            bigrams.append(bigram)\n",
    "        text_add = ' '.join(text.split()[1:])\n",
    "        text_add_new = re.findall(r'[^\\s]+[\\s][^\\s]+', text_add)\n",
    "        for bigram_add in text_add_new:\n",
    "            bigrams.append(bigram_add)\n",
    "    return bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2e6fdfe8-f338-4a41-8cee-fef4ea0765e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 87/87 [00:00<00:00, 24102.01it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 86/86 [00:00<00:00, 26721.25it/s]\n"
     ]
    }
   ],
   "source": [
    "bigrams_positive = bigrams_search(X_train[y_train == 1])\n",
    "bigrams_negative = bigrams_search(X_train[y_train == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f8c5c0e0-b9e8-4ab4-ae96-948028ab5115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# смотрим на частотность биграмм, создаем список биграмм позитивных и негативных отзывов, смотрим пересечение\n",
    "dict_positive_bigr = Counter(bigrams_positive)\n",
    "dict_negative_bigr = Counter(bigrams_negative)\n",
    "\n",
    "set_positive_bigr = set(bigrams_positive)\n",
    "set_negative_bigr = set(bigrams_negative)\n",
    "in_both_bigr = set_positive_bigr & set_negative_bigr\n",
    "\n",
    "list_positive_bigr = list(set_positive_bigr)\n",
    "list_negative_bigr = list(set_negative_bigr)\n",
    "list_in_both_bigr = list(in_both_bigr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5773eebe-7c14-45b5-87ee-82585f31b24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  убираем пересечение из списков, чистим списки по частотности\n",
    "f = 0\n",
    "l = 0\n",
    "while f < len(list_positive_bigr):\n",
    "    if list_positive_bigr[f] in list_in_both_bigr or dict_positive_bigr[list_positive_bigr[f]] < 3:\n",
    "        list_positive_bigr.pop(f)\n",
    "    else:\n",
    "        f += 1\n",
    "\n",
    "while l < len(list_negative_bigr):\n",
    "    if list_negative_bigr[l] in list_in_both_bigr or dict_negative_bigr[list_negative_bigr[l]] < 3:\n",
    "        list_negative_bigr.pop(l)\n",
    "    else:\n",
    "        l += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f759f72b-1d71-4d6c-9f10-c0ceb0b5b539",
   "metadata": {},
   "outputs": [],
   "source": [
    "only_positive_bigr = set(list_positive_bigr)\n",
    "only_negative_bigr = set(list_negative_bigr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2bb93684-7e2c-4a6b-98ad-b211098544c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для предсказания тональности по биграммам\n",
    "def predict_tone_bigr(arr, pos_l, neg_l):\n",
    "    ans = []\n",
    "    for text in arr:\n",
    "        content = set(re.findall(r'[^\\s]+[\\s][^\\s]+', text)) | set(re.findall(r'[^\\s]+[\\s][^\\s]+', ' '.join(text.split()[1:])))\n",
    "        if len(content & pos_l) > len(content & neg_l):\n",
    "            ans.append(1)\n",
    "        else:\n",
    "            ans.append(0)\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "15074f34-70d1-4af7-bbc6-ff754d552d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# предсказания на тренировочной и тестовой выборках\n",
    "predicted_train_bigr = predict_tone_bigr(X_train, only_positive_bigr, only_negative_bigr)\n",
    "predicted_test_bigr = predict_tone_bigr(X_test, only_positive_bigr, only_negative_bigr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0c9c0cfb-bb41-4486-b06e-d17840bdf6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train = 0.7976878612716763\n",
      "test = 0.64\n"
     ]
    }
   ],
   "source": [
    "# выводим accuracy для тренировочной и тестовой выборок\n",
    "print(f\"train = {accuracy_score(predicted_train_bigr, y_train)}\")\n",
    "print(f\"test = {accuracy_score(predicted_test_bigr, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c1012024-48d8-4a77-b8ad-6d6d7a8791c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# реализация второго способа\n",
    "vect = CountVectorizer(min_df = 10)\n",
    "X_train_bow = vect.fit_transform(X_train).toarray()\n",
    "X_test_bow = vect.transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "099778b8-4336-4c6e-bc25-bcd554860b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для предсказания целевой переменной по векторам\n",
    "def predict_new_way(k, y_train, X_train, X_test):\n",
    "    # сортирую полученные значения, выводя их индексы, оставляю k нужных\n",
    "    # здесь я с помощью евклидовой метрики вычисляю расстояние между объектами тестовой и тренировочной выборки\n",
    "    # потом сортирую полученные значения, выводя их индексы, оставляю k нужных\n",
    "    index = np.argsort(((((X_test[:, np.newaxis, :] - X_train[np.newaxis, :, :])**2).sum(axis=2))**0.5), axis = -1)[:, :k]\n",
    "    # вывожу моду среди значений по индексам\n",
    "    return st.mode(np.array(y_train)[index], axis=1).mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7c697645-37c4-489a-a542-90c8412c714f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# предсказание на тестовой выборке\n",
    "predicted_new_way = predict_new_way(3, y_train, X_train_bow, X_test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2f3969d9-0625-4e03-b365-d8b1ac585062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7066666666666667\n"
     ]
    }
   ],
   "source": [
    "# выводим accuracy для тестовой выборки\n",
    "print(accuracy_score(predicted_new_way, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
